# Web Scraping Using Selenium Package in Python 
##                          -- Data ETL Process

Step1: Use ‘webdriver’ function to automatically open browser, click the right buttons, and read (or download) the targeted data tables (or files) from a website, with ‘logging’ function being applied to track related information at the same time;

Step2: Manipulate data based on requirements 
       (for example, extracting key columns from data files, merging multiple dataframes together, etc.);
       
Step3: Transfer dataframe to the XML format and load XML object into the corresponding database table;

Stpe4: Automatically send related information and error messages to specified email addresses.

